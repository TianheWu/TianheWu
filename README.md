### Hi, I'm Tianhe Wu ðŸ‘‹

[![Email](https://img.shields.io/badge/-tianhe_wu@foxmail.com-green?style=flat-square&labelColor=grey&logo=Gmail&logoColor=white&link=mailto:tianhe_wu@foxmail.com)](tianhe_wu@foxmail.com)
[![ZhiHu](https://img.shields.io/badge/Intro-ZhiHu-blue)](https://www.zhihu.com/people/ru-ci-zhe-ban-91-2)
![visitors](https://visitor-badge.laobi.icu/badge?page_id=TianheWu/TianheWu)
[![GitHub Followers](https://img.shields.io/github/followers/TianheWu?style=social)](https://github.com/TianheWu)

- Postgraduate student at Tsinghua University
- Fields: **Image Quality Assessment and Perceptual Optimization**
- How to reach me: wth22@mails.tsinghua.edu.cn

**Researching Repository**
| Topic        | Title           | Details           |
| ------------- |-------------|-------------|
| IQA & MLLM| [[ECCV 24] A Comprehensive Study of Multimodal Large Language Models for Image Quality Assessment](https://github.com/TianheWu/MLLMs-for-IQA) [![paper](https://img.shields.io/badge/arXiv-Paper-green.svg)](https://arxiv.org/abs/2403.10854) [![GitHub Stars](https://img.shields.io/github/stars/TianheWu/MLLMs-for-IQA?style=social)](https://github.com/TianheWu/MLLMs-for-IQA) [![GitHub Forks](https://img.shields.io/github/forks/TianheWu/MLLMs-for-IQA?style=social)](https://github.com/TianheWu/MLLMs-for-IQA) | We probe the capability of **MLLMs for IQA** |
| Omnidirectional Image Quality Assessment| [[NeurIPS 23] Assessor360: Multi-sequence Network for Blind Omnidirectional Image Quality Assessment](https://github.com/TianheWu/Assessor360/tree/master) &emsp;   [![paper](https://img.shields.io/badge/arXiv-Paper-green.svg)](https://arxiv.org/abs/2305.10983) [![GitHub Stars](https://img.shields.io/github/stars/TianheWu/Assessor360?style=social)](https://github.com/TianheWu/Assessor360) [![GitHub Forks](https://img.shields.io/github/forks/TianheWu/Assessor360?style=social)](https://github.com/TianheWu/Assessor360)     |    We focus on solving the quality assessment issues in **novel scenario (VR)** |
| Image Quality Assessment| [[CVPRW 22] MANIQA: Multi-dimension Attention Network for No-Reference Image Quality Assessment](https://github.com/IIGROUP/MANIQA) [![paper](https://img.shields.io/badge/arXiv-Paper-green.svg)](https://arxiv.org/abs/2204.08958) [![GitHub Stars](https://img.shields.io/github/stars/IIGROUP/MANIQA?style=social)](https://github.com/IIGROUP/MANIQA) [![GitHub Forks](https://img.shields.io/github/forks/IIGROUP/MANIQA?style=social)](https://github.com/IIGROUP/MANIQA)      |    We won the first place in the ***NTIRE2022 Perceptual Image Quality Assessment Challenge Track 2 No-Reference competition***|
| Image Quality Assessment| [[CVPRW 22] Attention Helps CNN See Better: Hybrid Image Quality Assessment Network](https://github.com/IIGROUP/AHIQ) &emsp;&emsp;&emsp;&emsp;&emsp; [![paper](https://img.shields.io/badge/arXiv-Paper-green.svg)](https://arxiv.org/abs/2204.10485)  [![GitHub Stars](https://img.shields.io/github/stars/IIGROUP/AHIQ?style=social)](https://github.com/IIGROUP/AHIQ)   [![GitHub Forks](https://img.shields.io/github/forks/IIGROUP/AHIQ?style=social)](https://github.com/IIGROUP/AHIQ)  |    We won the first place in the ***NTIRE2022 Perceptual Image Quality Assessment Challenge Track 1 Full-Reference competition***|
